{
  "hash": "9c427eaf707ff1e3dbd1a784c531e17a",
  "result": {
    "engine": "julia",
    "markdown": "---\ntitle: \"Probability Models and EDA\"\nsubtitle: \"Lecture 03\"\nauthor: \"Vivek Srikrishnan\"\ncourse: \"BEE 4850\"\ninstitution: \"Cornell University\"\ndate: \"January 26, 2026\"\nformat:\n    revealjs: default\n    beamer: default\nengine: julia\nfilters:\n  - code-fullscreen\n---\n\n\n\n\n\n\n\n# Review\n\n## Probability Fundamentals\n\n- Bayesian vs. Frequentist Interpretations\n- Distributions reflect assumptions on probability of data.\n- Normal distributions: \"least informative\" distribution for a given mean/variance.\n- Fit distributions by maximizing likelihood.\n- Communicating uncertainty: confidence vs. predictive intervals.\n\n# Probability Models\n\n## Science as Decision-Making Under Uncertainty\n\n:::: {.columns}\n::: {.column width=60%}\nGoal is to draw insights:\n\n- About causes and effects;\n- About interventions\n\nfrom a limited (and noisy) set of data.\n\n:::\n\n::: {.column width=40%}\n![XKCD 2440](https://imgs.xkcd.com/comics/epistemic_uncertainty_2x.png){width=90%}\n\n::: {.caption}\nSource: [XKCD 2440](https://xkcd.com/2440)\n:::\n:::\n::::\n\n::: {.notes}\nThese decisions are complicated by model simplifications and observational uncertainties.\n\nSo we can never actually \"know\" something is true: we instead assess the consistency of evidence with predictions from theory.\n\nBut often the predictions are not black-and-white and must be understood probabilistically.\n:::\n\n## Why Do We Need Models For Data?\n\n- **Data are imperfect**: Data $X$ are only one realization of the data that **could** have been observed and/or we can only measure indirect proxies of what we care about.\n- Over time, statisticians learned to treat these imperfections as the results of **random** processes (for some of this history, see @Hacking1990-yr), requiring probability models.\n- **All methods for data analysis assume a probability model even when they pretend otherwise**.\n\n## Uses of Models\n\nWhat can we use a probability model for?\n\n1. **Summaries** of data: store $y = f(\\mathbf{x})$ instead of all data points $(y, x_1, \\ldots, x_n)$\n2. **Smooth** values by removing noise\n3. **Predict** new data (interpolation/extrapolation): $\\hat{f} = f(\\hat{\\mathbf{x}})$\n4. **Infer** relationships between variables (interpret coefficients of $f$)\n\n## Predicting Random Variables\n\nLet's say that we want to predict the value of a variable $y \\sim Y$. We need a criteria to define the \"best\" point prediction.\n\nReasonable starting point: \n\n$$\\text{MSE}(m) = \\mathbb{E}\\left[(Y - m)^2\\right]$$\n\n## MSE As (Squared) Bias + Variance\n\n$$\\begin{aligned}\n\\mathbb{V}(Y) &= \\mathbb{E}\\left[(Y - \\mathbb{E}[Y])^2\\right] \\\\\n&= \\mathbb{E}\\left[Y^2 - 2Y\\mathbb{E}[Y] + \\mathbb{E}[Y]^2\\right] \\\\\n&= \\mathbb{E}[Y^2] - 2\\mathbb{E}[Y]^2 + \\mathbb{E}[Y]^2 = \\mathbb{E}[Y^2] - \\mathbb{E}[Y]^2 .\n\\end{aligned}$$\n\n::: {.fragment .fade-in}\n$$\\Rightarrow \\text{MSE}(m) = \\mathbb{E}\\left[(Y - m)^2\\right] = \\mathbb{E}\\left[(Y-m)\\right]^2 + \\mathbb{V}(Y - m).$$\n:::\n\n## Bias-Variance Decomposition of MSE\n\nThen:\n\n$$\\begin{aligned}\n\\text{MSE}(m) &= \\mathbb{E}\\left[(Y-m)\\right]^2 + \\mathbb{V}(Y - m)  \\\\\n&= \\mathbb{E}\\left[(Y-m)\\right]^2 + \\mathbb{V}(Y) \\\\\n&= \\left(\\mathbb{E}[Y] - m\\right)^2 + \\mathbb{V}(Y).\n\\end{aligned}$$\n\nThis is the source of the so-called \"bias-variance tradeoff\" (more on this later).\n\n## Optimizing...\n\nWe want to find the minimum value of $\\text{MSE}(m)$ (denote the optimal prediction by $\\mu$):\n\n::: {.fragment .fade-in}\n$$\n\\begin{aligned}\n\\frac{d\\text{MSE}}{dm} &= -2(\\mathbb{E}[Y] - m) + 0 \\\\\n0 = \\left.\\frac{d\\text{MSE}}{dm}\\right|_{m = \\mu} &= -2(\\mathbb{E}[Y] - \\mu) \n\\end{aligned}$$\n\n$$\\Rightarrow \\mu = \\mathbb{E}[Y].$$\n:::\n\n## Expected Value As Best Prediction\n\nIn other words, **the best predicted value of a random variable is its expectation**.\n\nBut:\n\n1. We usually don't have enough data to know what $\\mathbb{E}[Y]$ is: need to make probabilistic assumptions;\n2. In many applications, we don't just want a point estimate, we need some estimate of ranges of values **we might observe**.\n\n## Linear Regression As A Probability Model\n\nThe \"simplest\" model is **linear**:\n\n:::: {.columns}\n::: {.column width=50%}\n$$\\begin{aligned}\ny_i &\\sim N(\\mu_i, \\sigma^2) \\\\\n\\mu_i &= \\sum_j \\beta_j x^j_i\n\\end{aligned}\n$$\n:::\n::: {.column width=50%}\n$$\\begin{aligned}\ny_i &= \\sum_j \\beta_j x^j_i + \\varepsilon_i \\\\\n\\varepsilon_i &\\sim N(0, \\sigma^2)\n\\end{aligned}\n$$\n:::\n::::\n\n\n## Why Linear Models?\n\n:::: {.columns}\n::: {.column width=60%}\nTwo main reasons to use linear models/normal distributions:\n\n1. **Inferential**: \"Least informative\" distribution assuming only finite mean/variance;\n2. **Generative**: Central Limit Theorem (summed fluctuations are asymptotically normal)\n\n:::\n::: {.column width=40%}\n![Weight stack Gaussian distribution](https://i.redd.it/zl5mo1n45wyb1.jpg)\n\n::: {.caption}\nSource: r/GymMemes\n:::\n:::\n::::\n\n::: {.notes}\nOne key thing: normal distributions are the \"least informative\" distribution given constraints on mean and variance. So all else being equal, this is a useful machine if all we're interested in are those two moments.\n:::\n\n## Linear Regression As Probability Model\n\n$$\ny = \\underbrace{\\sum_j \\beta_j x^j_i)}_{\\mathbb{E}[y | x^j]} + \\underbrace{\\varepsilon_i}_{\\text{noise}}, \\quad \\varepsilon_i \\sim N(0, \\sigma^2)\n$$\n\n1. $\\mathbb{E}[y | x^j]$: Best linear prediction of $y$ conditional on choice of predictors $x^j$.\n2. The noise defines the probability distribution (here: Gaussian) of the observations.\n\n\n## Implications of Gaussian Noise\n\nWithout explicit modeling of sources of measurement uncertainty, in LR we can't separate a noisy system state (due to *e.g.* omitted variables) from measurement error (more on this later).\n\n$$\n\\begin{array}{l}\nX \\sim N(\\mu_1, \\sigma_1^2) \\\\\nY \\sim N(\\mu_2, \\sigma_2^2) \\\\\nZ = X + Y\n\\end{array}\n\\qquad \\Rightarrow \\qquad Z \\sim N(\\mu_1 + \\mu_2, \\sigma_1^2 + \\sigma_2^2)\n$$\n\n\n# Exploratory Data Analysis\n\n## You Can Always Fit Models...\n\n:::: {.columns}\n::: {.column width=50%}\nBut not all models **are theoretically justifiable**.\n:::\n::: {.column width=50%}\n![Ian Malcolm meme](memes/ian_malcolm_should_model.png)\n:::\n::::\n\n## Some Implications of Mis-Specification\n\n- Biased estimates (expected value from the model does not match \"true\" expected value);\n- Incorrect inferences or inappropriate understandings of relationships/causality.\n- Over/under-confident risk assessments.\n\n## Data Generation Approximates Reality\n\n:::: {.columns}\n::: {.column width=33%}\n![Estimand Estimator Cake](memes/estimand_cake.png){width=100%}\n:::\n::: {.column width=33%}\n::: {.fragment .fade-in}\n![Estimand Estimator Cake](memes/estimator_cake.png){width=100%}\n:::\n:::\n::: {.column width=33%}\n::: {.fragment .fade-in}\n![Estimate Cake](memes/estimate_cake.png){width=100%}\n:::\n:::\n::::\n\n::: {.caption}\nSource: Richard McElreath\n:::\n\n::: {.notes}\nGoal is to start with some \"true\" process, then apply a procedure (experimental/observational + statistical) and recover what is hopefully a good estimate.\n\nBut lots can go wrong in this process!\n:::\n\n\n## How Do We Choose What To Model?\n\n![XKCD 2620](https://imgs.xkcd.com/comics/health_data.png)\n\n::: {.caption}\nSource: [XKCD 2620](https://xkcd.com/2620/)\n:::\n\n## How Do We Choose What To Model?\n\nDeveloping suitable models often starts with both **exploratory data analysis (EDA)** and **theoretical reasoning**.\n\n::: {.incremental}\n1. **EDA**: examining patterns/relationships with visual (plots, clustering) or quantitative (correlations).\n2. **Theory**: Avoids \"data dredging\" or \"mining,\" which can find spurious correlations or patterns which are misleading without broader context about data-generating mechanisms.\n:::\n\n\n## Exploratory Data Analysis\n\n- Will see many examples of this throughout the semester.\n- Try to impose as few assumptions as possible.\n- Often useful to start with **scatterplots**: one variable (typically independent) on the $x$-axis, another (typically dependent) on the $y$-axis.\n- Time series: **time always goes on the $x$-axis**.\n- Boxplots for comparison quantiles/ranges of variables or groups of data.\n\n## Common EDA Approaches\n\n- Data summaries (quantiles, mean/median, max/min, etc.)\n- Correlations\n- **Plot data** (from multiple perspectives)\n- Clustering (do you need multiple models?)\n\n## Anscombe's Quartet\n\n:::: {.columns}\n\n::: {.column width=40%}\nFour datasets, all with the same means, variances, correlations, and regression lines.\n\nShows the importance of visualization!\n:::\n::: {.column width=60%}\n![Anscombe's Quartet](figures/Anscombe.svg)\n\n::: {.caption}\nSource: [Wikipedia](https://en.wikipedia.org/wiki/Anscombe%27s_quartet)\n:::\n:::\n::::\n\n## Considerations When Plotting\n\n- Worry about the vertical scale\n    - Are you exaggerating small changes? Downplaying meaningful changes?\n    - \"Adjust vertical scale of data\" to reflect meaningful changes and \"Vertical scale should always include zero\" are conflicting advice.\n- Need to be thoughtful: **there is no such thing as objectively \"correct\" visualizations**, just **honest** visualizations. \n\n## Information Channels\n\nA *channel* is a mechanism for encoding information.\n\n::: {.fragment .fade-in}\nExamples:\n\n- Color (Hue/Saturation/Luminescence)\n- Position (1D/2D/3D)\n- Size (Length/Area/Volume)\n- Angle\n:::\n\n## Ordered vs. Categorical Attributes\n\nThe channels available depend on the type of attribute:\n\n- **Ordered** attributes can be \n  - *Ordinal*: Ranking, no meaning to distance;\n  - *Quantitative*: Measure of magnitude which supports arithmetic comparison;\n- **Categorical** attributes are unordered.\n\n## Channel Effectiveness: Ordered Data\n\n:::: {.columns}\n::: {.column width=75%}\n![](figures/ordered-channels.png){fig-align=center}\n:::\n::: {.column width=25%}\n::: {.caption}\nChannels for ordered data, arranged top-to-bottom from more to less effective (channels in the right column are less effective than those in the left). Modified from @Healy2018-zx after @Munzner2014-pj.\n:::\n:::\n::::\n\n## Channel Effectiveness: Categorical Data\n\n:::: {.columns}\n::: {.column width=75%}\n![](figures/categorical-channels.png){fig-align=center width=5in}\n:::\n::: {.column width=25%}\n::: {.caption}\nChannels for categorical data, arranged top-to-bottom from more to less effective. Modified from Healy (2018) after Munzer (2014).\n:::\n:::\n::::\n\n## Preattentive Popout\n\n:::: {.columns}\n::: {.column width=30%}\nTry to make your key features \"pop out\" to the viewer during the pre-attentive scan.\n\n::: {.caption}\nSearching for the blue circle becomes harder. Adapted from @Healy2018-zx.\n:::\n:::\n::: {.column width=70%}\n\n::: {.cell execution_count=1}\n``` {.julia .cell-code code-fold=\"true\"}\nnpt = 20\ndist = Distributions.Product(Uniform.([0, 0], [1, 1]))\npts = Tuple.(eachcol(rand(dist, npt)))\nblueidx = rand(1:npt)\np1 = scatter(pts[1:end .!= blueidx], color=:red, xticks=:false, yticks=:false, legend=:false, markersize=5, title=\"Color Only, N=20\", framestyle=:box)\nscatter!(p1, pts[blueidx, :], color=:blue, markersize=5)\n\nnpt = 100\npts = Tuple.(eachcol(rand(dist, npt)))\nblueidx = rand(1:npt)\np2 = scatter(pts[1:end .!= blueidx], color=:red, xticks=:false, yticks=:false, legend=:false, markersize=5, title=\"Color Only, N=100\", framestyle=:box)\nscatter!(p2, pts[blueidx, :], color=:blue, markersize=5)\n\nnpt = 20\npts = Tuple.(eachcol(rand(dist, npt)))\nblueidx = rand(1:npt)\np3 = scatter(pts[1:end .!= blueidx], color=:blue, markershape=:utriangle, xticks=:false, yticks=:false, legend=:false, markersize=5, title=\"Shape Only, N=20\", framestyle=:box)\nscatter!(p3, pts[blueidx, :], color=:blue, markersize=5, markershape=:circle)\n\nnpt = 100\npts = Tuple.(eachcol(rand(dist, npt)))\nblueidx = rand(1:npt)\np4 = scatter(pts[1:end .!= blueidx], color=:blue, markershape=:utriangle, xticks=:false, yticks=:false, legend=:false, markersize=5, title=\"Shape Only, N=100\", framestyle=:box)\nscatter!(p4, pts[blueidx, :], color=:blue, markersize=5, markershape=:circle)\n\nplot(p1, p2, p3, p4, layout=(2, 2), size=(800, 500))\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n![](lecture02-1-probmodels_files/figure-beamer/cell-4-output-1.svg){fig-pos='H'}\n:::\n:::\n\n\n\n:::\n::::\n\n## Color Schemes\n\nDifferent color schemes are appropriate depending on whether the data is *sequential*, *divergent*, or *unordered*.\n\n::: {.callout-important}\n### Appropriate Color Schemes\n\nColor schemes should be *perceptually uniform* to preserve a mapping between changes in perceived colors and changes in attribute values. \n\nTry to also choose color schemes which avoid confusing people who are color blind.\n:::\n\n\n## Color Schemes\n\n**Good news**: Most plotting libraries include a wide variety of perceptually uniform, color-blind safe color schemes.\n\n**Bad news**: These are not usually the defaults (in particular, avoid \"rainbow\" color schemes).\n\n## Sequential Color Schemes\n\nSequential schemes change in intensity from low to high as the value changes.\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n![](lecture02-1-probmodels_files/figure-beamer/cell-5-output-1.svg){fig-align='center'}\n:::\n:::\n\n\n\n## Divergent Color Schemes\n\nDivergent schemes intensify in two directions from a zero or mean value.\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n![](lecture02-1-probmodels_files/figure-beamer/cell-6-output-1.svg){}\n:::\n:::\n\n\n\n## Unordered Color Schemes\n\nUnordered schemes are appropriate for categorical data.\n\n::: {.cell execution_count=1}\n\n::: {.cell-output .cell-output-display execution_count=1}\n![](lecture02-1-probmodels_files/figure-beamer/cell-7-output-1.svg){}\n:::\n:::\n\n\n\n\n\n## Some Caveats\n\n::: {.incremental}\n- There is no recipe to effective visualization. Everything depends on your data and the story you want to tell.\n- This also means that defaults from data visualization packages are usually bad.\n- Principles are largely based on Western (American/European) norms and may not translate perfectly.\n- A lot of these guidelines are based on average outcomes, there is likely to be a lot of individual variation.\n:::\n\n\n\n\n# Key Points\n\n## Probability Models\n\n- Almost anything we want to use data for involves an assumption about the underlying probability model for the data.\n- Our goal this semester is to develop a toolkit to specify, test, and use these probability models.\n\n## EDA/Data Visualization\n\n- No such thing as \"objectively best\" visualization.\n- Need to be thoughtful about the story you're trying to tell.\n- Usually involves a lot of experimentation to make important features of the data pop out.\n- **EDA**: Try to make as few assumptions as possible (e.g. look at the raw data, not \"smoothed\" versions).\n\n## Data Visualization Suggestions\n\n- Some key degrees of freedom: vertical scale, information channels.\n- **Don't add unnecessary artifacts!** Easy to get \"cute\" and distract from core message.\n- Start simple (scatterplots, boxplots, histograms)\n\n# Upcoming Schedule\n\n## Next Classes\n\n**Wednesday**: Linear Regression (Examples/Why It Works)\n\n**Friday**: Data Visualization Lab (come prepared with a visualization and its underlying dataset).\n\n## Assessments\n\n**Homework 1** Due Friday, 2/6.\n\n# References\n\n## References (Scroll for Full List)\n\n",
    "supporting": [
      "lecture02-1-probmodels_files/figure-beamer"
    ],
    "filters": []
  }
}